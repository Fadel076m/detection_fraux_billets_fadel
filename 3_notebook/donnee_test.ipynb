{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45af11a0-c085-4d0c-baf3-ff2113e2380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6ec9bc2-7e15-4064-8624-7e89c684be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_csv(model_path, scaler_path, csv_file_path):\n",
    "    \"\"\"\n",
    "    Charge un modèle et fait des prédictions sur des données depuis un fichier CSV\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Chemin vers le modèle sauvegardé\n",
    "        scaler_path (str): Chemin vers le scaler sauvegardé\n",
    "        csv_file_path (str): Chemin vers le fichier CSV contenant les nouvelles données\n",
    "    \"\"\"\n",
    "    # Charger le modèle et le scaler\n",
    "    model = joblib.load(model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    # Charger les nouvelles données avec le bon séparateur\n",
    "    new_data = pd.read_csv(csv_file_path, sep=';')\n",
    "    \n",
    "    # Afficher les colonnes disponibles pour le débogage\n",
    "    print(\"Colonnes disponibles dans le CSV:\", new_data.columns.tolist())\n",
    "    \n",
    "    # Définir les caractéristiques attendues et leurs alias possibles\n",
    "    feature_mapping = {\n",
    "        'diagonal': ['diagonal', 'diagonale', 'diag'],\n",
    "        'height_left': ['height_left', 'hauteur_gauche', 'h_left', 'h_gauche'],\n",
    "        'height_right': ['height_right', 'hauteur_droite', 'h_right', 'h_droite'],\n",
    "        'margin_low': ['margin_low', 'marge_bas', 'margin_bottom', 'marge_basse'],\n",
    "        'margin_up': ['margin_up', 'marge_haut', 'margin_high', 'marge_haute'],\n",
    "        'length': ['length', 'longueur', 'long', 'lng']\n",
    "    }\n",
    "    \n",
    "    # Trouver les noms de colonnes correspondants\n",
    "    selected_features = []\n",
    "    available_columns = new_data.columns.tolist()\n",
    "    \n",
    "    for standard_name, possible_names in feature_mapping.items():\n",
    "        found = False\n",
    "        for possible_name in possible_names:\n",
    "            if possible_name in available_columns:\n",
    "                selected_features.append(possible_name)\n",
    "                found = True\n",
    "                print(f\"Utilisation de '{possible_name}' pour '{standard_name}'\")\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            raise ValueError(f\"Aucune colonne correspondante trouvée pour la caractéristique: {standard_name}. \"\n",
    "                           f\"Colonnes disponibles: {available_columns}\")\n",
    "    \n",
    "    # Vérifier que nous avons le bon nombre de caractéristiques\n",
    "    if len(selected_features) != 6:\n",
    "        raise ValueError(f\"Nombre de caractéristiques incorrect. Attendu: 6, Trouvé: {len(selected_features)}\")\n",
    "    \n",
    "    # Sélectionner les caractéristiques\n",
    "    X_new = new_data[selected_features]\n",
    "    \n",
    "    # Renommer les colonnes pour la cohérence (optionnel)\n",
    "    X_new.columns = list(feature_mapping.keys())\n",
    "    \n",
    "    # Appliquer le préprocessing\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "    \n",
    "    # Faire des prédictions\n",
    "    predictions = model.predict(X_new_scaled)\n",
    "    probabilities = model.predict_proba(X_new_scaled)\n",
    "    \n",
    "    # Créer un DataFrame avec les résultats\n",
    "    results = pd.DataFrame({\n",
    "        'Prédiction': ['Vrai' if pred == 1 else 'Faux' for pred in predictions],\n",
    "        'Confiance_Vrai': [f\"{prob[1]:.2%}\" for prob in probabilities],\n",
    "        'Confiance_Faux': [f\"{prob[0]:.2%}\" for prob in probabilities]\n",
    "    })\n",
    "    \n",
    "    # Combiner avec les données originales\n",
    "    final_results = pd.concat([new_data.reset_index(drop=True), results], axis=1)\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ada83ac-2ee8-4c6d-bbc5-3ab4527bb490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes disponibles dans le CSV: ['diagonal', 'height_left', 'height_right', 'margin_low', 'margin_up', 'length']\n",
      "Utilisation de 'diagonal' pour 'diagonal'\n",
      "Utilisation de 'height_left' pour 'height_left'\n",
      "Utilisation de 'height_right' pour 'height_right'\n",
      "Utilisation de 'margin_low' pour 'margin_low'\n",
      "Utilisation de 'margin_up' pour 'margin_up'\n",
      "Utilisation de 'length' pour 'length'\n",
      "Prédictions terminées avec succès!\n",
      "\n",
      "Résultats:\n",
      " diagonal  height_left  height_right  margin_low  margin_up  length Prédiction Confiance_Vrai Confiance_Faux\n",
      "   171.81       104.86        104.95        4.52       2.89  112.83       Vrai         84.00%         16.00%\n",
      "   171.46       103.36        103.66        3.77       2.99  113.09       Vrai        100.00%          0.00%\n",
      "   172.69       104.48        103.50        4.40       3.54  109.93       Faux          5.50%         94.50%\n",
      "   171.36       103.91        103.94        3.62       3.01  113.51       Vrai         99.50%          0.50%\n",
      "   171.73       104.28        103.46        4.04       3.48  112.54       Vrai         64.00%         36.00%\n",
      "   171.17       103.74        104.08        4.42       2.95  112.81       Vrai         96.50%          3.50%\n",
      "   172.34       104.18        103.85        4.58       3.26  112.81       Vrai         96.00%          4.00%\n",
      "   171.88       103.76        104.08        3.98       2.92  113.08       Vrai        100.00%          0.00%\n",
      "   172.47       103.92        103.67        4.00       3.25  112.85       Vrai        100.00%          0.00%\n",
      "   172.47       104.07        104.02        4.04       3.25  113.45       Vrai        100.00%          0.00%\n",
      "   171.83       104.14        103.62        3.16       3.18  113.22       Vrai        100.00%          0.00%\n",
      "   171.84       104.79        104.00        3.88       3.27  113.08       Vrai         97.50%          2.50%\n",
      "   171.65       104.00        104.53        4.11       2.96  110.24       Faux         24.50%         75.50%\n",
      "   172.20       104.35        103.67        4.44       3.38  113.65       Vrai         99.00%          1.00%\n",
      "   172.06       103.87        103.83        4.09       2.92  113.19       Vrai        100.00%          0.00%\n",
      "   171.73       103.92        103.74        4.43       2.78  112.98       Vrai        100.00%          0.00%\n",
      "   171.30       104.19        103.70        4.12       2.82  112.87       Vrai        100.00%          0.00%\n",
      "   171.88       104.47        103.45        4.56       3.33  113.01       Vrai         97.00%          3.00%\n",
      "   172.47       103.89        104.14        3.74       3.28  113.47       Vrai        100.00%          0.00%\n",
      "   171.90       103.67        103.15        4.55       3.15  113.12       Vrai        100.00%          0.00%\n",
      "   171.87       103.91        103.96        3.74       2.97  113.59       Vrai        100.00%          0.00%\n",
      "   171.56       104.47        104.04        3.77       2.99  113.09       Vrai         98.50%          1.50%\n",
      "   172.24       104.11        103.55        5.02       3.63  111.33       Faux          1.00%         99.00%\n",
      "   172.49       104.12        104.33        5.93       3.09  111.56       Faux          1.50%         98.50%\n",
      "   171.74       104.17        104.56        5.54       3.05  111.67       Faux          0.00%        100.00%\n",
      "   171.68       104.28        103.46        4.04       3.29  111.85       Faux         22.50%         77.50%\n",
      "   171.94       104.36        104.01        3.98       3.35  111.83       Faux         21.50%         78.50%\n",
      "   171.93       104.15        103.98        4.57       3.57  112.71       Faux         23.00%         77.00%\n",
      "   171.55       104.20        104.49        5.52       3.54  109.93       Faux          0.00%        100.00%\n",
      "   172.20       104.56        103.58        5.19       3.62  111.17       Faux          0.50%         99.50%\n",
      "   171.56       103.65        103.75        4.85       3.56  111.31       Faux          4.00%         96.00%\n",
      "   172.48       104.41        104.47        4.81       3.62  111.31       Faux          2.50%         97.50%\n",
      "   171.34       104.43        104.28        4.70       3.39  111.01       Faux          0.50%         99.50%\n",
      "   172.65       104.00        104.53        5.69       3.41  111.09       Faux          1.00%         99.00%\n",
      "   171.78       104.31        103.82        6.19       3.25  111.14       Faux          0.00%        100.00%\n",
      "   171.99       104.28        104.48        5.27       3.46  110.94       Faux          0.00%        100.00%\n",
      "\n",
      "Résumé: 20 vrais billets, 16 faux billets\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    # Chemins vers vos fichiers\n",
    "    model_path = \"../2_model/best_model_rf.pkl\"  # Remplacez par votre chemin\n",
    "    scaler_path = \"../2_model/scaler.pkl\"  # Remplacez par votre chemin\n",
    "    csv_path = \"billets_test_fadel.csv\"  # Remplacez par le chemin de votre fichier CSV\n",
    "    \n",
    "    # Faire les prédictions\n",
    "    try:\n",
    "        predictions = predict_from_csv(model_path, scaler_path, csv_path)\n",
    "        print(\"Prédictions terminées avec succès!\")\n",
    "        print(\"\\nRésultats:\")\n",
    "        print(predictions.to_string(index=False))\n",
    "        \n",
    "        # Statistiques summary\n",
    "        genuine_count = sum(1 for pred in predictions['Prédiction'] if pred == 'Vrai')\n",
    "        fake_count = len(predictions) - genuine_count\n",
    "        print(f\"\\nRésumé: {genuine_count} vrais billets, {fake_count} faux billets\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10147692-5173-4d85-8f55-c580c3372f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "#import numpy as np\n",
    "\n",
    "# Charger le modèle et le scaler\n",
    "#model = joblib.load('../2_model/best_model_rf.pkl')\n",
    "#scaler = joblib.load('../2_model/scaler.pkl')\n",
    "\n",
    "# Données d'un nouveau billet (à adapter avec vos mesures)\n",
    "#new_bill = pd.read_csv(\"data.csv\", sep = \";\")  # length, height_left, height_right, margin_up, margin_low, diagonal\n",
    "\n",
    "# Appliquer le préprocessing\n",
    "#new_bill_scaled = scaler.transform(new_bill)\n",
    "\n",
    "# Faire la prédiction\n",
    "#prediction = model.predict(new_bill_scaled)\n",
    "#probability = model.predict_proba(new_bill_scaled)\n",
    "\n",
    "# Afficher le résultat\n",
    "#result = \"FAUX\" if prediction[0] == 1 else \"VRAI\"\n",
    "#confidence = probability[0][1] if prediction[0] == 1 else probability[0][0]\n",
    "\n",
    "#print(f\"Prédiction: Le billet est {result}\")\n",
    "#print(f\"Confiance: {confidence:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4cd8e0-07d0-4ca5-b8f0-6b7efb3df8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
